{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0, 23],\n",
       "       [ 0,  0,  1,  2,  3,  4,  5,  6],\n",
       "       [ 3,  4,  0,  0,  0,  0,  0,  0]], dtype=int16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFSET = 8\n",
    "trajectory = [[23], [1,2,3,4,5,6], [1,2,3,4,0,0,0,0,0,0]]\n",
    "keras.preprocessing.sequence.pad_sequences(trajectory, maxlen=OFFSET, dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:/Users/abdul/Desktop/forest_python/'\n",
    "data_path = os.path.join(base_path, 'data')\n",
    "pickle_folder = os.path.join(data_path, 'pickles')\n",
    "trips_file_path = os.path.join(data_path, 'map_matched_all/')\n",
    "mapped_dict_file_name = 'mapped_dict.json'\n",
    "nodes_file_name = 'chengdu_nodes.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_count = 6\n",
    "root_dir = os.listdir(data_path)\n",
    "root_folder = []\n",
    "for i in range(1, step_count+1):\n",
    "    for d in root_dir:\n",
    "        if f'map_matched_csv_{i}' in d:\n",
    "            root_folder.append(os.path.join(data_path, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_files(folder):\n",
    "    gps_folders = os.listdir(folder)\n",
    "    valid_files = []\n",
    "    for gps_folder in gps_folders:\n",
    "        gps_folder_path = os.path.join(folder, gps_folder)\n",
    "        all_files = os.listdir(gps_folder_path)\n",
    "        for f in all_files:\n",
    "            f_path = os.path.join(gps_folder_path, f)\n",
    "            valid_files.append(f_path)\n",
    "    return valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "def get_full_df(valid_files):\n",
    "    df = None \n",
    "    pbar = tqdm(total=len(valid_files))\n",
    "    for i, f in enumerate(valid_files):\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            _df = pd.read_csv(f)\n",
    "        except:\n",
    "            continue\n",
    "        if df is None:\n",
    "            df = _df\n",
    "        else:\n",
    "            df = df.append(_df)\n",
    "    pbar.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary():\n",
    "    with open(os.path.join(data_path, mapped_dict_file_name), 'r') as mapped_dict:\n",
    "        return json.load(mapped_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dict = load_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_mapper(arr):\n",
    "    ret_arr = []\n",
    "    for e in arr:\n",
    "        if str(e) not in mapped_dict: return np.array(ret_arr).astype('int16')\n",
    "        ret_arr.append(mapped_dict[str(e)])\n",
    "    return np.array(ret_arr).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vectors(_df):\n",
    "    Y = df['destination'].astype('string')\n",
    "    Y = dict_mapper(Y)\n",
    "    \n",
    "    X1 = df['priors']\n",
    "    X1 = list(map(ast.literal_eval, X1)) \n",
    "    _X1 = []\n",
    "\n",
    "    _X2 = []\n",
    "\n",
    "    index_delete = []\n",
    "\n",
    "    for i in range(len(X1)):\n",
    "        t = X1[i]\n",
    "        if len(t) > 8:\n",
    "            index_delete.append(i)\n",
    "            continue\n",
    "        ndarr = dict_mapper(t)\n",
    "        \n",
    "        _X1.append(ndarr)\n",
    "\n",
    "        ndarr = np.array([])\n",
    "        _X2.append(ndarr)\n",
    "\n",
    "    X1 = _X1\n",
    "    X2 = _X2\n",
    "\n",
    "    Y = np.delete(Y, index_delete)\n",
    "    \n",
    "    max_len1 = 0\n",
    "    for x in X1:\n",
    "        if max_len1 < len(x):\n",
    "            max_len1 = len(x)\n",
    "    max_len2 = 0\n",
    "    for x in X2:\n",
    "        if max_len2 < len(x):\n",
    "            max_len2 = len(x)\n",
    "            \n",
    "    X1 = keras.preprocessing.sequence.pad_sequences(X1, maxlen=max_len1, dtype='int16')\n",
    "    X2 = keras.preprocessing.sequence.pad_sequences(X2, maxlen=max_len2, dtype='int16')\n",
    "\n",
    "    all_features = len(mapped_dict)\n",
    "    X = np.hstack((X1,X2))\n",
    "    return X, Y\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save(x, y, step):\n",
    "    pickle.dump( x, open( os.path.join(pickle_folder, f\"X_{step}.pkl\"), \"wb\" ) )\n",
    "    pickle.dump( y, open( os.path.join(pickle_folder, f\"Y_{step}.pkl\"), \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vectors():\n",
    "    for i in range(len(root_folder)):\n",
    "        vf = get_valid_files(root_folder[i])\n",
    "        df = get_full_df(vf)\n",
    "        x, y = make_vectors(df)\n",
    "        save(x, y, i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weight_dict():\n",
    "    train_folder = os.path.join(data_path, 'map_matched')\n",
    "    gps_folders = os.listdir(train_folder)\n",
    "    all_files = []\n",
    "    for g in gps_folders:\n",
    "        g_path = os.path.join(train_folder, g)\n",
    "        t_f = os.listdir(g_path)\n",
    "        for t in t_f:\n",
    "            all_files.append(os.path.join(g_path, t))\n",
    "    \n",
    "    weights = {}\n",
    "    mapped_dict = load_dictionary()\n",
    "    pbar = tqdm(total=len(all_files))\n",
    "    for f in all_files:\n",
    "        pbar.update(1)\n",
    "        with open(f, 'r') as content:\n",
    "            trips = json.load(content)\n",
    "            for t in trips:\n",
    "                for p in t:\n",
    "                    m_id = mapped_dict[str(p)]\n",
    "                    w = weights.get(m_id, 0)\n",
    "                    weights[m_id] = w + 1\n",
    "    pbar.close()\n",
    "    json.dump(weights, open('../weights.json', 'w'), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9863c50896814475843a5d7584f38b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1556.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_weight_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
